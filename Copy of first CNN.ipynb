{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from this script : \n",
    "\n",
    "https://www.kaggle.com/jeffd23/the-nature-conservancy-fisheries-monitoring/deep-learning-in-the-deep-blue-lb-1-279/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import numpy,pandas,matplotlib\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import scikit learn libraries\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# import keras libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D,Dense,Dropout,Flatten,MaxPooling2D,ZeroPadding2D,Activation\n",
    "from keras.optimizers import Adam,RMSprop\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import image\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = 'train/train/'\n",
    "TEST_DIR = 'test_stg1/test_stg1/'\n",
    "FISH_CLASSES = [\"ALB\",\"BET\",\"DOL\",\"LAG\",\"NoF\",\"OTHER\",\"SHARK\",\"YFT\"]\n",
    "ROWS = 90\n",
    "COLS = 160\n",
    "CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c945d001dfe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvgg_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m123.68\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m116.779\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m103.939\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mvgg_preprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mvgg_mean\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "vgg_mean = np.array([123.68, 116.779, 103.939], dtype=np.float32).reshape((3,1,1))\n",
    "def vgg_preprocess(x):\n",
    "    x = x - vgg_mean\n",
    "    return x[:, ::-1]\n",
    "\n",
    "def get_images(fish):\n",
    "    \"\"\"Load files from train folder\"\"\"\n",
    "    fish_dir = TRAIN_DIR+ '{}'.format(fish)\n",
    "    images = [fish+'/'+im for im in os.listdir(fish_dir+'/')]\n",
    "    return images\n",
    "\n",
    "def read_image(img_path):\n",
    "    \"\"\"Read and resize individual images\"\"\"\n",
    "    img = image.load_img(img_path,target_size=(90,160))\n",
    "    x = image.img_to_array(img)\n",
    "    x = vgg_preprocess(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "files = []\n",
    "y_all = []\n",
    "\n",
    "for fish in FISH_CLASSES:\n",
    "    fish_files = get_images(fish)\n",
    "    files.extend(fish_files)\n",
    "    \n",
    "    y_fish = np.tile(fish, len(fish_files))\n",
    "    y_all.extend(y_fish)\n",
    "    print(\"{0} photos of {1}\".format(len(fish_files), fish))\n",
    "    \n",
    "y_all = np.array(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_all = np.ndarray((len(files), CHANNELS,ROWS, COLS), dtype=np.uint8)\n",
    "\n",
    "for i, im in enumerate(files): \n",
    "    X_all[i] = read_image(TRAIN_DIR+im)\n",
    "    if i%1000 == 0: print('Processed {} of {}'.format(i, len(files)))\n",
    "\n",
    "print(X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_all = LabelEncoder().fit_transform(y_all)\n",
    "y_all = np_utils.to_categorical(y_all)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_all, y_all, \n",
    "                                                    test_size=0.2, random_state=23, \n",
    "                                                    stratify=y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-4)\n",
    "objective = 'categorical_crossentropy'\n",
    "\n",
    "\n",
    "model = VGG16(weights = \"imagenet\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=objective, optimizer = \"sgd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Original fit function\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto')        \n",
    "        \n",
    "model.fit(X_train, y_train, batch_size=64, nb_epoch=1,\n",
    "              validation_split=0.2, verbose=1, shuffle=True, callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2416 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 1066s - loss: 2.0223 - val_loss: 1.9712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xfb2e876c18>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=20, nb_epoch=1,\n",
    "              validation_split=0.2, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "756/756 [==============================] - 106s   \n",
      "Validation Log Loss: 1.9626615209869607\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_valid, verbose=1)\n",
    "print(\"Validation Log Loss: {}\".format(log_loss(y_valid, preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 145s   \n"
     ]
    }
   ],
   "source": [
    "test_files = [im for im in os.listdir(TEST_DIR)]\n",
    "test = np.ndarray((len(test_files), ROWS, COLS, CHANNELS), dtype=np.uint8)\n",
    "\n",
    "for i, im in enumerate(test_files): \n",
    "    test[i] = read_image(TEST_DIR+im)\n",
    "    \n",
    "test_preds = model.predict(test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>ALB</th>\n",
       "      <th>BET</th>\n",
       "      <th>DOL</th>\n",
       "      <th>LAG</th>\n",
       "      <th>NoF</th>\n",
       "      <th>OTHER</th>\n",
       "      <th>SHARK</th>\n",
       "      <th>YFT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>img_00005.jpg</td>\n",
       "      <td>0.63992</td>\n",
       "      <td>0.512145</td>\n",
       "      <td>0.436537</td>\n",
       "      <td>0.426624</td>\n",
       "      <td>0.516825</td>\n",
       "      <td>0.449915</td>\n",
       "      <td>0.464633</td>\n",
       "      <td>0.521914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>img_00007.jpg</td>\n",
       "      <td>0.63992</td>\n",
       "      <td>0.512145</td>\n",
       "      <td>0.436537</td>\n",
       "      <td>0.426624</td>\n",
       "      <td>0.516825</td>\n",
       "      <td>0.449915</td>\n",
       "      <td>0.464633</td>\n",
       "      <td>0.521914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>img_00009.jpg</td>\n",
       "      <td>0.63992</td>\n",
       "      <td>0.512145</td>\n",
       "      <td>0.436537</td>\n",
       "      <td>0.426624</td>\n",
       "      <td>0.516825</td>\n",
       "      <td>0.449915</td>\n",
       "      <td>0.464633</td>\n",
       "      <td>0.521914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>img_00018.jpg</td>\n",
       "      <td>0.63992</td>\n",
       "      <td>0.512145</td>\n",
       "      <td>0.436537</td>\n",
       "      <td>0.426624</td>\n",
       "      <td>0.516825</td>\n",
       "      <td>0.449915</td>\n",
       "      <td>0.464633</td>\n",
       "      <td>0.521914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>img_00027.jpg</td>\n",
       "      <td>0.63992</td>\n",
       "      <td>0.512145</td>\n",
       "      <td>0.436537</td>\n",
       "      <td>0.426624</td>\n",
       "      <td>0.516825</td>\n",
       "      <td>0.449915</td>\n",
       "      <td>0.464633</td>\n",
       "      <td>0.521914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image      ALB       BET       DOL       LAG       NoF     OTHER  \\\n",
       "0  img_00005.jpg  0.63992  0.512145  0.436537  0.426624  0.516825  0.449915   \n",
       "1  img_00007.jpg  0.63992  0.512145  0.436537  0.426624  0.516825  0.449915   \n",
       "2  img_00009.jpg  0.63992  0.512145  0.436537  0.426624  0.516825  0.449915   \n",
       "3  img_00018.jpg  0.63992  0.512145  0.436537  0.426624  0.516825  0.449915   \n",
       "4  img_00027.jpg  0.63992  0.512145  0.436537  0.426624  0.516825  0.449915   \n",
       "\n",
       "      SHARK       YFT  \n",
       "0  0.464633  0.521914  \n",
       "1  0.464633  0.521914  \n",
       "2  0.464633  0.521914  \n",
       "3  0.464633  0.521914  \n",
       "4  0.464633  0.521914  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(test_preds, columns=FISH_CLASSES)\n",
    "submission.insert(0, 'image', test_files)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"test_cnn1.csv\",index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score : 1.96619\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALB' 'ALB' 'ALB']\n"
     ]
    }
   ],
   "source": [
    "print(np.tile(\"ALB\",3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rows = 90\n",
    "cols = 160\n",
    "\n",
    "def read_image(src):\n",
    "    \"\"\"Read and resize individual images\"\"\"\n",
    "    im = cv2.imread(src, cv2.IMREAD_COLOR)\n",
    "    im = cv2.resize(im, (cols, rows), interpolation=cv2.INTER_CUBIC)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_path = \"other/lion.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_version = read_image(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 160, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_version.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keras_version = image.img_to_array(image.load_img(img_path,target_size=(rows,cols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 90, 160)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_version.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
